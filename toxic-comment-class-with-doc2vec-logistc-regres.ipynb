{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n",
      "/kaggle/input/toxic-comment-model/doc2vec-toxic.model\n",
      "/kaggle/input/toxic-comment-model/doc2vec-toxic.model.docvecs.vectors_docs.npy\n",
      "/kaggle/input/test-features/Test_features_toxic_comment.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\r\n",
      "  inflating: train.csv               \r\n",
      "Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\r\n",
      "  inflating: test.csv                \r\n",
      "Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\r\n",
      "  inflating: sample_submission.csv   \r\n",
      "Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\r\n",
      "  inflating: test_labels.csv         \r\n"
     ]
    }
   ],
   "source": [
    "!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n",
    "!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
    "!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n",
    "!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')\n",
    "submission=pd.read_csv('sample_submission.csv')\n",
    "test_labels=pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3       00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4       00017695ad8997eb          I don't anonymously edit articles at all.\n",
       "...                  ...                                                ...\n",
       "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...\n",
       "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...\n",
       "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
       "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...\n",
       "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...\n",
       "\n",
       "[153164 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### So we can see that a comment can have multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['id']\n",
    "train_df.drop(cols_to_drop,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocessing Training Data\n",
    "\n",
    "pre-process each line (tokenize text into individual words, remove punctuation, set to lowercase, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There might be some missing values so we have to handle them as always\n",
    "COMMENT = 'comment_text'\n",
    "train_df[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "test_df[COMMENT].fillna(\"unknown\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def tokeniser_gen(df,tokens_only=False):\n",
    "   \n",
    "    for i,iterator in enumerate(range(len(df))):\n",
    "        line=df.loc[iterator]['comment_text']\n",
    "        tokens=gensim.utils.simple_preprocess(line)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "        \n",
    "train_corpus=list(tokeniser_gen(train_df))\n",
    "\n",
    "test_corpus = list(tokeniser_gen(test_df, tokens_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "refer [here](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Build Vocabulary\n",
    "Essentially, the vocabulary is a dictionary (accessible via model.wv.vocab) of all of the unique words extracted from the training corpus along with the count \n",
    "\n",
    "(e.g., model.wv.vocab['penalty'].count for counts for the word penalty).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/doc2vec-toxic-100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00026192  0.0247625  -0.04677513 -0.03049093  0.00798524  0.05021098\n",
      "  0.01348796  0.0634729   0.02222658 -0.05092812 -0.06360117  0.00370967\n",
      " -0.04261972 -0.00251006  0.04424752 -0.06525391  0.00286783 -0.05631689\n",
      "  0.00702617  0.02948709  0.05153012  0.05731047 -0.14501384 -0.11308805\n",
      "  0.09189925  0.01026158  0.01392639 -0.00034943 -0.03084719 -0.0343532\n",
      "  0.0914257   0.08337139 -0.14861494  0.22628593  0.07403352 -0.01998601\n",
      "  0.08459276 -0.00375962  0.10610422  0.12297155 -0.00825975 -0.00082397\n",
      " -0.00529838 -0.04928123 -0.04579074  0.02327015 -0.02610426 -0.11656953\n",
      "  0.09049954 -0.1305277   0.03517422  0.05614713  0.00462316 -0.06297098\n",
      "  0.07033511  0.06028103 -0.01410527  0.04165618  0.01875094 -0.05955436\n",
      "  0.01693773  0.07279351  0.04817581  0.00926701  0.15096577 -0.03808413\n",
      " -0.02743369  0.04082724 -0.01457325 -0.01788765  0.0613092   0.04229861\n",
      "  0.07595947 -0.00593287  0.03732304 -0.02287145 -0.05347645  0.04444833\n",
      "  0.12764192  0.08956876 -0.04809857  0.09381608 -0.19266073 -0.06665571\n",
      "  0.02317357  0.03028851  0.03389268 -0.02728777  0.08613002  0.03171341\n",
      " -0.07831053  0.0454031   0.02955483 -0.00931775 -0.01546087  0.01741295\n",
      " -0.06517588 -0.05960884  0.0076081  -0.04378257]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model_df = Doc2Vec.load(\"/kaggle/working/doc2vec-toxic-100.model\")\n",
    "vector = model_df.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_test_fea=[]\n",
    "for i in range(len(test_corpus[:])):\n",
    "    vector=model_df.infer_vector(test_corpus[i])\n",
    "    empty_test_fea.append(vector)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_features=empty_test_fea[:]\n",
    "test_features=np.array(test_features)\n",
    "test_features.shape\n",
    "np.save('/kaggle/working/Test_features_toxic_comment',test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Loading training and testing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 100)\n",
      "(159571, 100)\n"
     ]
    }
   ],
   "source": [
    "train_features=np.load('/kaggle/working/doc2vec-toxic-100.model.docvecs.vectors_docs.npy')\n",
    "test_features=np.load('/kaggle/working/Test_features_toxic_comment.npy')\n",
    "print(test_features.shape)\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Basic Naive Bayes Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_features\n",
    "test_x = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "x = sparse.csr_matrix(x)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Fit a model for one dependent at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r=pr(1,y) / pr(0,y)\n",
    "#     r = np.log(pr(1,y) / pr(0,y))#ignored values were going to negative  infinity so instead  directly took ratio\n",
    "# becuase  actually we  just want ratio \n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.8746171514398359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit severe_toxic\n",
      "CV score for class severe_toxic is 0.8426826446716434\n",
      "fit obscene\n",
      "CV score for class obscene is 0.8900476565384459\n",
      "fit threat\n",
      "CV score for class threat is 0.852271707587117\n",
      "fit insult\n",
      "CV score for class insult is 0.8823941122662068\n",
      "fit identity_hate\n",
      "CV score for class identity_hate is 0.8780029085287673\n",
      "Total CV score is 0.8700026968386694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "preds = np.zeros((len(test_df), len(label_cols)))\n",
    "\n",
    "\n",
    "scores=[]\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m = LogisticRegression(C=4,max_iter=2000)\n",
    "    r = get_mdl(train_df[j])\n",
    "    x_nb = x.multiply(r)\n",
    "    y=train_df[j]\n",
    "    cv_score = np.mean(cross_val_score(m, x_nb, y, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(j, cv_score))\n",
    "    m.fit(x_nb, y)\n",
    "    preds[:,i] = m.predict_proba(np.multiply(test_x,r))[:,1]\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submid = pd.DataFrame({'id': submission[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#  Not for this kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df\n",
    "# clean=train_df.loc[(train_df.toxic==0) & (train_df.severe_toxic==0) & (train_df.obscene==0)&(train_df.threat==0)&(train_df.insult==0)&(train_df.identity_hate==0)]\n",
    "# toxic=train_df.loc[(train_df.toxic==1) ]\n",
    "# severe_toxic=train_df.loc[ (train_df.severe_toxic==1)]\n",
    "# obscene=train_df.loc[ (train_df.obscene==1)]\n",
    "# threat=train_df.loc[(train_df.threat==1)]\n",
    "# insult=train_df.loc[(train_df.insult==1)]\n",
    "# identity_hate=train_df.loc[(train_df.identity_hate==1)]\n",
    "# print(clean.shape,toxic.shape,severe_toxic.shape,obscene.shape,threat.shape,insult.shape,identity_hate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean=clean.loc[:,'comment_text'].to_frame()\n",
    "# toxic=toxic.loc[:,'comment_text'].to_frame()\n",
    "# severe_toxic=severe_toxic.loc[:,'comment_text'].to_frame()\n",
    "# obscene=obscene.loc[:,'comment_text'].to_frame()\n",
    "# threat=threat.loc[:,'comment_text'].to_frame()\n",
    "# insult=insult.loc[:,'comment_text'].to_frame()\n",
    "# identity_hate=identity_hate.loc[:,'comment_text'].to_frame()\n",
    "# print(clean.shape,toxic.shape,severe_toxic.shape,obscene.shape,threat.shape,insult.shape,identity_hate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean['label']=[0]*len(clean)\n",
    "# toxic['label']=[1]*len(toxic)\n",
    "# severe_toxic['label']=[2]*len(severe_toxic)\n",
    "# obscene['label']=[3]*len(obscene)\n",
    "# threat['label']=[4]*len(threat)\n",
    "# insult['label']=[5]*len(insult)\n",
    "# identity_hate['label']=[6]*len(identity_hate)\n",
    "# print(clean.shape,toxic.shape,severe_toxic.shape,obscene.shape,threat.shape,insult.shape,identity_hate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean=clean.append(toxic,ignore_index=True)\n",
    "# clean=clean.append(severe_toxic,ignore_index=True)\n",
    "# clean=clean.append(obscene,ignore_index=True)\n",
    "# clean=clean.append(threat,ignore_index=True)\n",
    "# clean=clean.append(insult,ignore_index=True)\n",
    "# trainer=clean.append(identity_hate,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # There might be some missing values so we have to handle them as always\n",
    "# COMMENT = 'comment_text'\n",
    "# trainer[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "# test_df[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "\n",
    "# def tokeniser_gen(df,tokens_only=False):\n",
    "   \n",
    "#     for i,iterator in enumerate(range(len(df))):\n",
    "#         line=df.loc[iterator]['comment_text']\n",
    "#         tokens=gensim.utils.simple_preprocess(line)\n",
    "#         if tokens_only:\n",
    "#             yield tokens # for testing we are only creting tokens of a sentence not tagging them\n",
    "#         else:\n",
    "#             #for training only\n",
    "#             yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "#             #for training doc2vec we need to tag documents here we are just tagging them by integers\n",
    "\n",
    "        \n",
    "# train_corpus_new=list(tokeniser_gen(trainer))\n",
    "\n",
    "# test_corpus_new = list(tokeniser_gen(test_df, tokens_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_new.build_vocab(train_corpus_new)\n",
    "# model_new.train(train_corpus, total_examples=model_new.corpus_count, epochs=model_new.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_new.save(\"/kaggle/working/doc2vec-toxic-75-new.model\")\n",
    "# from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "# model_df_new = Doc2Vec.load(\"/kaggle/working/doc2vec-toxic-75-new.model\")\n",
    "# vector = model_df_new.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "# print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_test_fea=[]\n",
    "# for i in range(len(test_corpus[:5])):\n",
    "#     vector=model_df_new.infer_vector(test_corpus[i])\n",
    "#     empty_test_fea.append(vector)\n",
    "# #     print(i)\n",
    "\n",
    "# test_features=empty_test_fea[:]\n",
    "# test_features=np.array(test_features)\n",
    "# test_features.shape\n",
    "# np.save('/kaggle/working/Test_features_toxic_comment',test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features=np.load('/kaggle/working/doc2vec-toxic-75-new.model.docvecs.vectors_docs.npy')\n",
    "# test_features=np.load('/kaggle/working/Test_features_toxic_comment.npy')\n",
    "# print(test_features.shape)\n",
    "# print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pr(y_i, y):\n",
    "#     p = x[y==y_i].sum(0)\n",
    "#     return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "# x = train_features\n",
    "\n",
    "# test_x = test_features\n",
    "\n",
    "# from scipy import sparse\n",
    "# x = sparse.csr_matrix(x)\n",
    "# imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imp.fit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x[4:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d=clf.predict_proba(test_x[4:])\n",
    "\n",
    "# print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_index_col = np.argmax(d, axis=1)\n",
    "# max_index_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('sahi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# ls=[]\n",
    "# clf = LogisticRegression(solver='sag',max_iter=1000)\n",
    "# cv_score = ls.append(cross_val_score(clf, x, trainer['label'], cv=10, scoring='roc_auc'))\n",
    "# clf.fit(x, trainer['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mdl(y):\n",
    "#     y = y.values\n",
    "#     r=pr(1,y) / pr(0,y)\n",
    "# #     r = np.log(pr(1,y) / pr(0,y))#ignored values were going to negative  infinity so instead  directly took ratio\n",
    "# # becuase  actually we  just want ratio \n",
    "#     m = LogisticRegression(C=4,max_iter=1000)\n",
    "    \n",
    "#     x_nb = x.multiply(r)\n",
    "#     return m.fit(x_nb, y), r\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# preds = np.zeros((len(test_df), len(label_cols)))\n",
    "\n",
    "\n",
    "\n",
    "# for i, j in enumerate(label_cols):\n",
    "#     print('fit', j)\n",
    "#     m,r = get_mdl(train_df[j])\n",
    "#     preds[:,i] = m.predict_proba(np.multiply(test_x,r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=\"he  is fat\"\n",
    "# f=gensim.utils.simple_preprocess(f)\n",
    "# m1 = Doc2Vec.load(\"/kaggle/working/doc2vec-toxic-75.model\")\n",
    "# # vector1 = m1.infer_vector(f)\n",
    "# empty_test_fea1=[]\n",
    "# for i in range(1):\n",
    "#     vector1=m1.infer_vector(f)\n",
    "#     empty_test_fea1.append(vector1)\n",
    "#     print(i)\n",
    "# test_features1=empty_test_fea1[:]\n",
    "# test_features1=np.array(test_features1)\n",
    "# test_features1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# preds1 = np.zeros((1, len(label_cols)))\n",
    "\n",
    "\n",
    "\n",
    "# for i, j in enumerate(label_cols):\n",
    "#     print('fit', j)\n",
    "#     m,r = get_mdl(train_df[j])\n",
    "#     preds1[:,i] = m.predict_proba(np.multiply(test_features1,r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submid1 = pd.DataFrame({'id': submission[\"id\"]})\n",
    "# submission1 = pd.concat([submid1, pd.DataFrame(preds1, columns = label_cols)], axis=1)\n",
    "# submission1.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
