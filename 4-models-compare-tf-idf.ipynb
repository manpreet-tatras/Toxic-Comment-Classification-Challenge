{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":13,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\nrslt_df = df[(df['toxic'] == 0) & (df['severe_toxic'] == 0) & (df['obscene'] == 0) & (df['threat'] == 0) & (df['insult'] == 0) & (df['identity_hate'] == 0)]\nrslt_df2 = df[(df['toxic'] == 1) & (df['severe_toxic'] == 0) & (df['obscene'] == 0) & (df['threat'] == 0) & (df['insult'] == 0) & (df['identity_hate'] == 0)]\nnew1 = rslt_df[['id', 'comment_text', 'toxic']].iloc[:23891].copy() \nnew2 = rslt_df2[['id', 'comment_text', 'toxic']].iloc[:946].copy()\nnew = pd.concat([new1, new2], ignore_index=True)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=5)\nXv = vectorizer.fit(new['comment_text'])\nimport pickle","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(new[\"comment_text\"], new['toxic'], test_size=0.33)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n# vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=5)\nX1 = vectorizer.transform(X_train)\nX_test1= vectorizer.transform(X_test)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Original dataset shape %s' % Counter(y_train))\nsm = SMOTE(random_state=12)\nx_train_res, y_train_res = sm.fit_sample(X1, y_train)\nprint('Resampled dataset shape %s' % Counter(y_train_res))","execution_count":18,"outputs":[{"output_type":"stream","text":"Original dataset shape Counter({0: 16003, 1: 637})\nResampled dataset shape Counter({0: 16003, 1: 16003})\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"LOGISTIC REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nclf2 = LogisticRegression(C=0.1, solver='sag')\nscores = cross_val_score(clf2, x_train_res,y_train_res, cv=5,scoring='f1_weighted')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"array([0.9217432 , 0.94141017, 0.92594565, 0.93452301, 0.93438492])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_p1 = clf2.fit(x_train_res, y_train_res).predict(X_test1)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_test, y_p1)\nprint('Accuracy: %f' % accuracy)","execution_count":30,"outputs":[{"output_type":"stream","text":"Accuracy: 0.908137\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nz=1.96\ninterval = z * np.sqrt( (0.908137 * (1 - 0.908137)) / y_test.shape[0])\ninterval","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"0.0062528009129526945"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn import svm\nclf = svm.SVC(kernel='linear', C=1)\nscores = cross_val_score(clf,x_train_res,y_train_res, cv=5)\nscores","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"array([0.99422056, 0.99656304, 0.99703171, 0.99531323, 0.99640681])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ny_p2 = clf.fit(x_train_res, y_train_res).predict(X_test1)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_test, y_p2)\nprint('Accuracy: %f' % accuracy)","execution_count":28,"outputs":[{"output_type":"stream","text":"Accuracy: 0.963279\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nz=1.96\ninterval = z * np.sqrt( (0.963279 * (1 - 0.963279)) / y_test.shape[0])\ninterval","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"0.004071569944781895"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"RANDOM FOREST"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\nclf3 = RandomForestClassifier() #Initialize with whatever parameters you want to\n\n# 10-Fold Cross validation\nscores = cross_val_score(clf3,x_train_res,y_train_res, cv=5)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"array([0.98391128, 0.99968755, 0.99968755, 0.9993751 , 0.99953132])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_p3 = clf3.fit(x_train_res, y_train_res).predict(X_test1)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_p3)\nprint('Accuracy: %f' % accuracy)","execution_count":51,"outputs":[{"output_type":"stream","text":"Accuracy: 0.962669\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nz=1.96\ninterval = z * np.sqrt( (0.9629 * (1 - 0.9629)) / y_test.shape[0])\ninterval","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"0.004091722308937716"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"MULTINOMIAL NB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf4 = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\nscores = cross_val_score(clf4,x_train_res,y_train_res, cv=5)\ny_pred4 = clf4.fit(x_train_res, y_train_res).predict(X_test1)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"array([0.94611059, 0.9523512 , 0.94453992, 0.94766443, 0.95266365])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred4)\nprint('Accuracy: %f' % accuracy)","execution_count":41,"outputs":[{"output_type":"stream","text":"Accuracy: 0.893376\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nz=1.96\ninterval = z * np.sqrt( (0.893376 * (1 - 0.893376)) / y_test.shape[0])\ninterval","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"0.006681488572468208"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}